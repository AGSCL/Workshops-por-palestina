---
title: "Introducción al análisis de clases latentes"
date: last-modified
date-format: "D [d]e MMM, YYYY"
author: "Andrés González-Santa Cruz"
subtitle: "¿De cuál de las siguientes maneras, si es que hay alguna, has solidarizado con Gaza?"
institute: "Estudiante Doctorado en Salud Pública, Investigador joven, nDP"
editor: source
format: 
  revealjs:
    theme: "mylibs/theme2.scss"
    transition: slide
    css: 
      - mylibs/animate.min.css
      - mylibs/ninjutsu.css
      - mylibs/logo.css      
    width: 1600
    height: 900      
    fig-cap-location: top
    lightbox: auto
    lang: es
    slide-number: true
    incremental: true
    self-contained: true # Embeds all assets locally
    navigation-mode: linear # Disable scroll-based navigation
    logo: "_style/logo-CDSP_gris.png"
    ratio: 16:9 # Slide aspect ratio    
    include-after-body: 
      - mylibs/collapseoutput.js
      - mylibs/zoom.html
      - mylibs/timer.html
    pdf-export: true # Enable PDF export
    code-fold: true
    code-summary: "expandir para código"
---

## Indice

```{r}
#| echo: true
#| include: true
#| code-fold: true
#| code-summary: "expandir para código"
#| fig-align: "center"
#| warnings: false
#| message: false
#| results: hide
#| label: "setup"

#eliminar archivos previos y limpiar la memoria del entorno
rm(list=ls());gc()

#Definir el repositorio sobre el que instalar los paquetes desde Chile
options(repos=structure(c(CRAN="https://cran.dcc.uchile.cl/"))) 

#ver si puede activarse un paquete; si no, lo instala
#para cambiar la fuente de las letras
if(!require(showtext)){install.packages("showtext")}
#para elaborar gráficos
if(!require(ggplot2)){install.packages("ggplot2")}
#para elaborar gráficos interactivos
if(!require(plotly)){install.packages("plotly")}
#Para separar gráficos
if(!require(grid)){install.packages("grid")}
#Para separar gráficos, ampliado
if(!require(gridExtra)){install.packages("gridExtra")}
#para mostrar imágenes
if(!require(magick)){install.packages("magick")}
#para hacer tablas e interactuar con informes
if(!require(knitr)){install.packages("knitr")}
#para manipular bases de datos
if(!require(tidyverse)){install.packages("tidyverse")}
#para importar y exportar bases de datos en distintos formatos
if(!require(rio)){install.packages("rio")}
#para explorar variables
if(!require(psych)){install.packages("psych")}
#para paralelizar los procesos en la CPU
if(!require(parallel)){install.packages("parallel")}
#hace lo mismo
if(!require(doParallel)){install.packages("doParallel")}

#Para llevar a cabo análissi de clases latentes
if(!require(glca)){install.packages("glca")}

#para generar gráficos esquemáticos
if(!require(DiagrammeR)){install.packages("DiagrammeR")}
#para exportar esos gráficos
if(!require(DiagrammeRsvg)){install.packages("DiagrammeRsvg")}
#para transformar gráficos en formato .svg
if(!require(rsvg)){install.packages("rsvg")}
#para visualizarlos en una presentación
if(!require(htmlwidgets)){install.packages("htmlwidgets")}
#permite limpiar bases de datos, entre otras funciones
if(!require(janitor)){install.packages("janitor")}

# Activar showtext
#showtext_auto()

# Agregar la fuente Oswald desde Google Fonts
#font_add_google(name = "Oswald", family = "Oswald")
```

- Problema /Caso de uso
- Definición, supuestos y lugar en familia de modelos, ventajas/limitaciones
- Aplicación: selección modelo (ajuste)
- Aplicación: clasificación (hard classification / modal)
- Qué reportar, mejores prácticas
- Extensiones: incorporar covariables (classify-analyse/1-step/3-step)
- Fuentes

::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`
- Me presento: mi nombre es Andrés González, soy psicólogo de profesion, estudiante del Doctorado de Salud Pública en la Universidad de Chile

- Yo aplico herramientas estadísticas, pero siempre intento trabajar con un bioestadístico, 
o consultartle. De la misma forma, es necesario que tenga en cuenta mi formación para que tome perspectiva del enfoque aplicado que veremos aquí.
:::

## Problema

:::: {.columns}

::: {.column width="45%"}
```{r}
#| echo: true
#| include: true
#| code-fold: true
#| fig-align: "left"
#| code-summary: "expandir para código"
#| warnings: false
#| message: false
#| label: "importar_bd"
#Importar base de datos. En este caso la obtuve de una carpeta personal. 
#Por tanto, para la ubicación del proyecto, retrodecedemos a la carpeta anterior que la contiene, 
#luego, voy a la carpeta ArabBarometer_WaveVIII_English_v1, y busco el archivo 
#ArabBarometer_WaveVIII_English_v1.csv

#Este archivo es un archivo separado por comas

#Si no, puede importarlos desde (ventana interactiva)
#arabebarometro<- rio::import(choose.files())
wdpath <- getwd()
arabebarometro<-
rio::import(paste0(gsub("palestine$","", wdpath), "ArabBarometer_WaveVIII_English_v2/ArabBarometer_WaveVIII_English_v3.csv"))

#Previsualizar base de datos
glimpse(arabebarometro, width = 40) 
```
<div style="text-align: center; font-size: small; font-style: italic;"> Fuente: <a href="https://www.arabbarometer.org/surveys/arab-barometer-wave-viii/#" target="_blank">Data Sets
Arab Barometer Wave VIII: Base de datos y Reporte técnico</a> </div>

::: {.nonincremental}
<div style="font-size: 45%; line-height: 0.9;">
**QKUW40: "¿De cuáles de las siguientes maneras, si es que hay alguna, ha mostrado usted solidaridad con Gaza? Por favor, dígame todas las que apliquen."**

1. Boicot a empresas que apoyan a Israel  
2. Seguimiento continuo de noticias relacionadas con la guerra  
3. Participación en actividades públicas de solidaridad  
4. Difusión de mensajes de solidaridad en redes sociales  
5. Donaciones monetarias a los residentes de Gaza  
90. Otro – Por favor, especifique: 
97. No he tomado ninguna de estas acciones
98. No sabe
99. Se niega a responder

Además, utilizaremos otras variables
</div>
:::
<!-- In which of the following ways, if any, have you stood in solidarity with Gaza? -->
:::

::: {.column width="5%"}

:::

::: {.column width="50%"}

Eliminamos casos con IDs inválidos (n= 2.400) y que tengan  al menos 2 perdidos en las variables de apoyo (n=9.609). Nos quedamos con 1.210 observaciones.

::: {.nonincremental}


```{r}
#| echo: true
#| include: true
#| code-fold: true
#| fig-align: "center"
#| code-summary: "expandir para código"
#| warnings: false
#| message: false
#| label: "seleccion_bd"

#para explorar variables de interés
#arabebarometro %>% dplyr::filter(rowSums(!is.na(select(., paste0("QKUW40_", c(1:5, 90, 97, 98, 99))))) > 0) |> glimpse()

arabebarometro_selected<-
arabebarometro |> 
  #descartamos aquellos que no tengan número de identificación de respuesta
    dplyr::filter(ID!="0") |>
    #vemos las preguntas de interés
    dplyr::select(dplyr::contains("QKUW40"),
      #seleccionamos el estatus ocupacional
      dplyr::contains("Q1005"),
      #seleccionamos el género (2. Mujer)
      dplyr::contains("Q1002"),
      #Tenencia de vivienda
      "Q1001G",
      #Jefatura de hogar
      "Q1001F"
      ) 
#eliminamos aquellos que notengan valores en ninguna de las variables de interés
arabebarometro_selected <- arabebarometro_selected[rowSums(!is.na( arabebarometro_selected[,paste0("QKUW40_", c(1:5, 90, 97, 98, 99))] )) > 1, ]
```

```{r }
#| echo: true
#| include: true
#| code-fold: true
#| fig-align: "center"
#| code-summary: "expandir para código"
#| warnings: false
#| message: false
#| fig.align: 'center'
#| label: "esquema"
#| fig.cap: "Esquema conceptual"
#| out-width: "100%"
#| fig.height: 2
#| eval: true

gr_lca_9 <- DiagrammeR::grViz("
digraph flowchart {
    fontname='Comic Sans MS'
    rankdir=TB; // Cambia la orientación a vertical (Top to Bottom)
    nodesep=0.4; // Reduce la separación horizontal entre nodos
    ranksep=0.4; // Reduce la separación vertical entre filas

    // Nodo principal de 'Clases latentes'
    LCA [label = 'Clases\\nlatentes',
         shape = circle,
         style = filled,
         color = lightgrey,
         fontsize=14]

    // Nodos con 9 opciones abreviadas
    Q1 [label = 'opc1', fontsize=11, shape = box]
    Q2 [label = 'opc2', fontsize=11, shape = box]
    Q3 [label = 'opc3', fontsize=11, shape = box]
    Q4 [label = 'opc4', fontsize=11, shape = box]
    Q5 [label = 'opc5', fontsize=11, shape = box]
    Q6 [label = 'opc90', fontsize=11, shape = box]
    Q7 [label = 'opc97', fontsize=11, shape = box]
    Q8 [label = 'opc98', fontsize=11, shape = box]
    Q9 [label = 'opc99', fontsize=11, shape = box]

    // Conexiones desde 'Clases latentes' a cada opción
    LCA -> {Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9}
}
")

gr_lca_9
```

:::

<div style="font-size: 90%; line-height: 0.9;">
- Manifestaciones de apoyo heterogéneas

- Pero...

- Grupos --> Patrones

- **¿Podremos identificarles y describirles?**

</div>
:::

::::

::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`
- Asumimos que hay manifestaciones de apoyo heterogéneas (¿este supuesto se ajusta a los datos?)
- Pero ciertas combinaciones de acciones que son comunes entre algun@s y distint@s de otr@s
- Suponemos que "pertenecen" a ciertos grupos (que no vemos directamente) que explican esos "patrones" y no otros
- ¿Podremos identificarles y describirles?
- Este enfoque es especialmente útil en ciencias sociales, del comportamiento y la salud, donde se presupone que los datos se generan a partir de una mezcla de distribuciones específicas para cada clase.
:::

## Antecedentes conceptuales

<!-- Definición, supuestos y lugar en familia de modelos, ventajas/limitaciones -->

:::: {.columns}

::: {.column width="50%"}

- Definición: ¿latentes?

- Supuestos

```{r}
#| echo: true
#| include: true
#| code-fold: true
#| fig-align: "center"
#| code-summary: "expandir para código"
#| warnings: false
#| message: false
#| fig.align: 'center'
#| label: "ejemplo"
#| fig.cap: "Ejemplo mezcla distribuciones subyacentes"
#| out-width: "50%"
#| fig-height: 2.5
# Generar datos simulados
set.seed(123)
x <- seq(0, 10, by = 0.1)  # Solo valores positivos

# Clase Latente 1: Weibull con cola más larga a la derecha
shape_weibull <- 2  # Forma de la Weibull
scale_weibull <- 4  # Escala para ajustar la dispersión
density_class1 <- dweibull(x, shape = shape_weibull, scale = scale_weibull)

# Clase Latente 2: distribución normal
density_class2 <- dnorm(x, mean = 6, sd = 2)

# Distribución observada: suma de las densidades (normalizada)
density_observed <- density_class1 + density_class2
density_observed <- density_observed / max(density_observed) * max(dnorm(x, mean = 5, sd = 2))

# Crear el dataframe
data <- data.frame(
    x = c(x, x, x),
    density = c(density_class1, density_class2, density_observed),
    group = rep(c("Latent Class 1", "Latent Class 2", "Observed Distribution"), each = length(x))
)

# Crear el gráfico
ggplot(data, aes(x= x, y= density, color= group, linetype= group)) +
  # Rellenar las áreas bajo las curvas de las clases latentes
  geom_area(data= subset(data, group== "Latent Class 1"), aes(fill= group), alpha= 0.2)+
  geom_area(data= subset(data, group== "Latent Class 2"), aes(fill= group), alpha= 0.2)+
  # Líneas para las densidades
  geom_line(size= 1) +
  # Defino el color para cada línea
  scale_color_manual(values= c("blue", "red", "black")) +
  # Defino el color de relleno para esas distribuciones
  scale_fill_manual(values= c("blue", "red", NA)) +
  # Defino el tipo de linea (interlineado) para cada una
  scale_linetype_manual(values= c("dashed", "dashed", "solid")) +
  # Doy nombre a los ejes x e y
  labs(x= "Units", y= "Density", color= "", linetype= "", fill= "") +
  # Superpongo nombres a las distribuciones con ubicaciones en coordenadas x e y y defino el color
  annotate("text", x= 2, y= 0.08, label= "Clase\nlatente 1", color= "blue", size= 6) +
  annotate("text", x= 7, y= 0.08, label= "Clase\nlatente 2", color= "red", size= 6) +
  annotate("text", x= 5, y= 0.20, label= "Distribución\nobservada", color= "black", size= 6)+
  # elimino información irrelevante, incluyendo la leyenda 
theme_void()+
theme(legend.position = "none")
```
<div style="text-align: center; font-size: small; font-style: italic;"> Adaptado de: <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC7746621/" target="_blank">Sinha et al 2021</a> </div>
<div style="font-size: 50%;">
|                 | Para Promedios        |                       | de Regresión                    |                           |
|-----------------|-----------------------|-----------------------|---------------------------------|---------------------------|
|                 | **Latente Continua**  | **Latente Discreta**  | **Latente Continua**            | **Latente Discreta**      |
| **Observado**   |                       |                       |                                 |                           |
| **Continua**    | Factorial             | Rasgos latentes       | Efectos aleatorios              | Mezcla finita             |
| **Discreta**    | TRI                   | Clases latentes       | Efectos aleatorios logísticos   | Logística, Mezcla finita  |
</div>
<div style="text-align: center; font-size: small; font-style: italic;"> Adaptado de: <a href="https://daob.nl/wp-content/uploads/2015/06/oberski-LCA.pdf" target="_blank">Oberski, 2016</a> </div>

::: 

::: {.column width="50%"}
```{r}
#| echo: true
#| include: true
#| code-fold: true
#| fig-align: "center"
#| code-summary: "expandir para código"
#| warnings: false
#| message: false
#| fig.align: 'center'
#| label: "ventajas-desventajas"
##| fig.cap: "Ventajas y desventajas"
#| out.height: "30%"
# Cargar las bibliotecas necesarias
library(ggplot2)
library(gridExtra)

ratio_plot <- 1.5

# Datos (sin cambios)
data <- data.frame(
  Categoria = c(rep("Ventajas", 3), rep("Limitaciones", 3)),
  Texto = c(
    "Probabilística",
    "Datos faltantes",
    "Criterios estadísticos",
    "Valores iniciales",
    "Computacionalmente\nintensivo",
    "Tamaño muestra"
  ),
  Posicion = c(1:3, 1:3)
)

# Función para crear gráficos con ajustes
crear_grafico <- function(data, color, titulo, shape) {
  ggplot(data, aes(x = 0, y = Posicion, label = Texto)) +
    geom_text(hjust = -0.05, color = color, size = 6 * ratio_plot) +
    geom_point(color = color, size = 5 * ratio_plot, shape = shape, fill = color) +
    xlim(0, 1) +
    theme_void() +
    ggtitle(titulo) +
    theme(
      plot.title = element_text(color = color, size = 16 * ratio_plot, face = "bold", hjust = 0.5), # Centrar título
      plot.margin = margin(2, 2, 2, 2, "mm") # Márgenes más pequeños en mm
    ) +
    scale_y_continuous(limits = c(0.5, 3.5), expand = c(0, 0)) # Ajustar límites del eje y
}

# Crear los gráficos usando la función
ventajas_plot <- crear_grafico(data[data$Categoria == "Ventajas", ], "darkgreen", "Ventajas", 24)
limitaciones_plot <- crear_grafico(data[data$Categoria == "Limitaciones", ], "darkred", "Limitaciones", 25)


# Combinar los gráficos con ajustes para reducir espacio
grid.arrange(
  ventajas_plot, limitaciones_plot,
  ncol = 2,
  widths = c(1, 1),
  padding = unit(0, "mm") # Eliminar padding entre gráficos
)
```

::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`

- Walter Weldon, biometrista británico, le preguntó a Pearson analizando mediciones de cangrejos, que las mediciones de diámetro de caparazón, etc., no distribuían de acuerdo a la "ley normal", ya que existían dos curvas. Gracias a Pearson, weldon descompuso la distribución en dos componentes normales, conforme al pensamiento de Galton de que las distribuciones eran o normales o MIXTURAS de normales. En un principio pensó que midió a especies distintas. (Madrid-Casado, 2014)
:::

### Utilidad

1. **Análisis sustantivo**

2. **Análisis longitudinal**

3. **Metodología de encuestas**

:::

::::

::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`
**Definición**= Statistical model in which parameters of interest differ across unobserved subgroups (“latent classes”; “mixtures”). Buscamos estimar los parámetros que describen estas clases (valores no observados que inferimos explican las respuestas en variables observadas, medidas y manifiestas, y se asumen que toman valores discretos; no se asume que poseen propiedades continuas como los rasgos latentes)
Buscamos estimar los parámetros del modelo que describen estas clases latentes, como:
- Las probabilidades de pertenecer a cada clase.
- Las distribuciones esperadas (prob. respuesta, por ej.) de las variables observadas dentro de cada clase.

- Pueden usarse como una técnica dirigida por los datos, como de tener fundamentos teóricos para utilizarlos. Centrado en las personas u observaciones //Análisis factorial o PCA, por ej., se centra en los ítems (vertical) [variable-centered], en reducir la dimensionalidad
- A diferencia de cluster, por ejemplo, se asume que las clases **existen** y son parte del proceso por el cual se generan los datos. Es más parsimoniosa y por tanto mejor para muestras pequeñas (Van Lissa et al., 2023)
-  Permite manejar datos perdidos (cuando no todos son perdidos), maneja variables de múltiples tipos

- Se ha usado como un término paraguas para muchos modelos con variables o medidas no observadas a través de indicadores. También se confunde con LCA con indicadores ordinales (Van Lissa et al., 2023)

**Supuestos**:
- Mezcla de distribuciones: Las respuestas observadas se explican como una combinación ponderada de distribuciones específicas de cada clase latente.
- Independencia condicional: Dentro de cada clase latente, las variables observadas son independientes.
- Se recomienda: Highly “discriminative” variables (necessary to create classes/subgroups) > variable design/selection
- Exhaustividad: Cada individuo pertenece a exactamente una clase latente
- A veces se puede relajar el supuesto de independencia condicional, pero hay que conocer a priori los datos y de donde provienen y la naturaleza de las covariables y su relación. Si no, usar factor mixture models o growth mixture models

**Tabla**
- Medias= Identificar patrones de respuesta o perfiles promedio. Nos centramos en el Y, en la medida de resumen por cada clase respecto a cómo esperamos que respondan y la proporción \pi esperada de individuos en cada clase.
- Regresión= Explicar/predecir una variable respuesta en base a predictores o VIs.
- Oberski: A different name for latent class analysis is “binomial (finite) mixture model”.
- Es un modelo probabilístico que asume que las relaciones entre las variables observadas se explican por una variable categórica no observada 

**Utilidad**
- 1) - Creación de tipologías de encuestados (ej.: tolerancia, valores, clase social). - Modelos multinivel no paramétricos.
- 2) - Estudio de datos de crecimiento o trayectorias a lo largo del tiempo.
- 3) - Análisis de patrones de datos faltantes o respuestas aberrantes. - Evaluación del desempeño de los cuestionarios.
:::

## Cómo lo hace

:::: {.columns}

::: {.column width="50%"}

- Qué queremos estimar

- Algoritmo EM

```{r}
#| label: "EM"
#| out.width: "80%"
#https://dreampuf.github.io/GraphvizOnline/
grViz("
digraph EM_Latent_Classes {
  graph [rankdir = TB]
  nodesep=0.4; // Reduce la separación horizontal entre nodos
  ranksep=0.4; // Reduce la separación vertical entre filas
  
  node [shape = rectangle, style = filled, fillcolor = lightgrey, fontname = Helvetica, fontsize=10]

  # Nodos
  A [label = '(0) Estimar parámetros iniciales']
  B [label = '(1) Calcular probabilidad posterior\n(estimación de clase latente)']
  C [label = '(2) Actualizar parámetros\n(con base en la probabilidad post)\n', fontsize=9]

  # Subgráficos para controlar alineaciones
  { rank = same; A }
  { rank = same; B }
  { rank = same; C }

  # Flechas
  A -> B
  B -> C [arrowhead = normal, dir = forward, tailport = w, headport = w]
  C -> B [arrowhead = normal, dir = forward, tailport = e, headport = e, constraint = false]
}
")
```
<div style="text-align: center; font-size: small; font-style: italic;"> Adaptado de: <a href="https://daob.nl/wp-content/uploads/2015/06/oberski-LCA.pdf" target="_blank">Oberski, 2016</a> </div>



:::

::: {.column width="50%"}

- Máxima local vs. global
- Valores iniciales

```{r}
#| label: "local maxima"
#| out.width: "70%"
#| fig.cap: "Soluciones locales vs. globales"

img <- image_read("_figs/valores_inicio.png")
cropped_img <- image_crop(img, geometry = "2500x1500+200+400")
cropped_img
```
<div style="text-align: center; font-size: small; font-style: italic;"> Adaptado de: <a href="https://www.risis2.eu/wp-content/uploads/2019/09/LCM-with-STATA_-Barbara_Antonioli_Mantegazzini_rev.pdf" target="_blank">Mantegazzini, 2019</a> </div>



- Ejemplo en esta [**página**](https://agscl3.shinyapps.io/Ejemplo_ACL/)

:::

::::

::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`
- Desde el **punto de vista de un psicólogo de profesión**
- Por lo que entiendo, la probabilidad de observar las respuestas de los sujetos, depende de la suma por cada clase de:
    - la probabilidad de que el sujeto pertenezca a la clase
    - multiplicado por la probabilidad de las respuestas específicas a las categorías de las variables manifiestas según cada clase (Veremos en su conjunto en los gráficos que vienen, en el de barra/área)
    - al sumar todo, tenemos la probabildiad total de las respuestas manifiestas observadas (datos)
- Pero la clase y la cantidad de clases existentes no las vemos. No vemos a qué clase pertenece cada individuo. Esos son los parámetros. Por tanto, tenemos que estimarlos para ver si se ajustan a los datos. Eso se hace mediante Expectation-Maximisation (EM), que permite manejar esta información "faltante"/incompleta.
- EXPECTATION: Calcula las probabilidades posteriores de pertenencia a cada clase para cada individuo, usando los parámetros actuales.
- MAXIMIZATION: Actualiza los parámetros del modelo (π y ρ) maximizando la verosimilitud, usando las probabilidades posteriores calculadas en el paso E. Este proceso se repite hasta que los parámetros convergen

- **Página**= 40% de los datos estarán en clase 1 ($\pi_1$) y el resto en clase 2 ($\pi_2$). $\rho_1$ (rho) la probabilidad de respuesta a "Sí" será de 0,8 a la primera pregunta, a la segunda, será de 0,3 ($\rho_2$).
- Primero, hacemos una suposición inicial sobre a qué grupo pertenece cada dato (calcula la probabilidad posterior  de cada observación pertenezca a cada clase, dado el modelo). Luego, mejoras tus suposiciones de $\pi$, $rho_1$ y $rho_2$ calculando las probabilidades para cada grupo. Repites estos pasos (suponer y mejorar) hasta que las respuestas no cambian mucho, es decir: converge (la log-verosimilitud no cambia).
- Los parámetros iniciales (como probabilidades de pertenencia a clases y probabilidades de respuesta condicionadas a las clases) se asignan aleatoriamente. Esos son los puntos de partida, pero puede que no encontremos el **máximo global**. Para ello generamos distintos puntos de partida.
- Vemos cómo mejora el modelo con cada iteración, hasta una determinada cantidad de iteraciones en que ya no mejora o muy poco. Vemos también cuál fue la menos sesgada.

- En el ejemplo, **poLCA** requiere variables politómicas, se pueden convertir las variables continuas (siempre con el riesgo de introducir sesgo; por ej., un día por distribuciones de semanas de embarazo, dividí en 25% los valores y los clasifiqué, pero sin reconocer el problema y la naturaleza. Luego hable con una matrona, y me proporcionó una clasificación mucho mejor de las semanas [21-25 de gestación, por ej.] )

- El algoritmo expectation-maximization (EM), si bien sirve cuando no converge la función de máxima verosimilitud (MLE), no son la MLE, porque la verosimilitud tiene una máxima local, por tanto si es una máxima local, las estimaciones producidas por el algoritmo de optimización dependen del punto de partida. Por tanto, el mismo ajuste
mediante distintos softwares podría producir distintos resultados.
- Para eso, se prueban muchos puntos de partida, y se seleccionan los resultados con la mayor verosimilitud. Para asegurarse que la máxima global verdadera está respondida, se pruebal muchos miles de valores iniciales. (Cislo et al 2021)

:::

## Aplicación (1)

- Muestra requerida (Nylund-Gibson & Choi, 2018; Weller et al., 2020)

- Clases pequeñas, inestables (<5%), poco replicables (Herle et al., 2020; Wolf, 2025)

- Variables manifiestas, categorías de respuesta e identificación

- Criterios de ajuste: BIC $arg\,min_M\,C(M)$, razón de verosimilitud $p<.05$, Entropía relativa $[0,1)$


::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`
- 300>= Nylund-Gibson and Choi (2018)
- Un heurístico de N>= 500 se ha sugerido (https://doi.org/10.1037/met0000486)
- Parece que entre N ~~300-1000 es el rango para funcionar bien
- Indicadores, más mejor, 4-20, depende
- O muestras dependiendo de los parámetros a estimar. Algunos dicen, por cada parámetro libre, 5 observaciones; otros, 20.
- 3 clases con una con 10% de la muestra; 2 con una con <15% muestra (Sinha 2019)
- Si la base es muy grande, podemos considerarlo (ej., <5%) (wolf et al)
- #parametros libres= (clases latentes - 1)+ (parámetros condicionales= sumar de 1 a m[var manifiestas]* (clases x (categorías/cada una -1)) )
$$(k-1)+ (\,\,\sum_{i=1}^{m}(k\times(c_i-1))\,\,)$$

- Tenemos información suficiente para estimar las clases latentes que postulamos? (ej., tenemos 3 variables manifiestas con 2 opciones de respuesta cada una y planeamos estimar 9 clases latentes. La combinatoria no da...). Un modelo  sobreidentificado es aquel que tneemos grados de libertad positivos para evaluar qué tan bien encaja el modelo y compararlo. Algunas opciones radican en fijar parámetros, agregar indicadores, o reducir el número de clases.
Por ejemplo, si tenemos 3 incógnitas y 2 ecuaciones, puedo estimar los valores de x, y, z que satisfagan las dos ecuaciones, pero si cambio algo de z  y ajustar x e y para que las ecuaciones sigan siendo válidas.
x+y+z=10,
2x−y+3z=5.
- Por tanto, no hay una única configuración porque faltan ecuaciones, por lo que hay muchas soluciones que encajan igual con los datos.

- π (pi): Probabilidades de clase latente - proporción de individuos en cada clase
- ρ (rho): Probabilidades condicionales de respuesta - probabilidad de cada respuesta dado que pertenece a una clase
- Las probabilidades posteriores indican la probabilidad de que cada individuo pertenezca a cada clase latente, dado su patrón de respuestas observadas


**Ajuste**
- BIC [k*ln(n)−2ln(L^)] [a más parámetros y a mayor tamaño de muestra, más se penaliza la complejidad]: confiable y debe ser reportado. N<300, incluir el criterio de Akaike [AIC=2k−2ln(L^)] [2k= más complejo (2 x npar); -2ln(L^)= menor ajuste, - menos max verosimilitud ]
- Elementos fuera de la diagonal en la matriz de probabildiades posteriores. 0,8 o 0,9 o más
- Entropía: la absoluta es poco interpretable. cuán certero es el modelo definiendo clases. >0,6 aceptable, o >0,8 bueno, capacidad de clasificación. La entropía suelen disminuir a medida que incrementan las clases (Zhang). Se utiliza la entropía relativ. Primero calculamos cuánta “mezcla de probabilidades” hay en los datos (entropía observada), luego la dividimos por lo peor que podría ser (entropía si todas las probabilidades fueran uniformes), y por último restamos a 1 para que un valor alto signifique “buena clasificación".
- Probabilidades posteriores promedio >.7 indican clases bien separadas (Nagin, 2005)
$$
\frac{1}{N} \sum_{i=1}^{N} P\bigl(C_i = \hat{k}_i \mid \text{datos}_i\bigr) > 0.7,
$$
donde \(\hat{k}_i = \arg\max_{1 \le k \le K} P(C_i = k \mid \text{datos}_i)\).
-Se promedian las probabilidades a posteriori “en la diagonal” (i.e., la probabilidad de la clase asignada) sobre todos los individuos, y si ese promedio supera 0.7, se considera que la separación entre clases es buena.

:::


## Aplicación (2)

:::: {.columns}

::: {.column width="50%"}

- Ver relación con otras variables

  + Clasificar-analizar

  + 1-step

  + 3-step

:::

::: {.column width="50%"}

```{r}
#| echo: true
#| include: true
#| code-fold: true
#| fig-align: "center"
#| code-summary: "expandir para código"
#| warnings: false
#| message: false
#| label: "ej-clasificaciones-exp"
#| out.height: "100%"
#| fig.show: "hold"
set.seed(2025)
n_individuos <- 10
clases <- paste0("Clase_", 1:3)

# Generar probabilidades aleatorias que suman 1 por individuo
prob_mat <- t(apply(matrix(runif(n_individuos * length(clases)), 
                           ncol = length(clases)), 1, function(x) x / sum(x)))
df_probs <- as_tibble(prob_mat) %>%
  set_names(clases) %>%
  mutate(ID = paste0("Obs ", sprintf("%02.0f",seq_len(n_individuos)))) %>%
  # Determinar clase dura: la que tiene probabilidad máxima
  rowwise() %>%
  mutate(
    Clase_dura = clases[which.max(c_across(all_of(clases)))]
  ) %>%
  ungroup()

# 2. Pasar a formato 'long' para ggplot
df_long <- df_probs %>%
  select(ID, all_of(clases), Clase_dura) %>%
  pivot_longer(cols = all_of(clases), 
               names_to = "Clase", 
               values_to = "Prob") %>%
  # Para ordenar las barras de arriba hacia abajo (opcional)
  mutate(ID = factor(ID, levels = paste0("Obs ", sprintf("%02.0f",seq_len(n_individuos)))))

# 3. Dibujar el gráfico
ggplot(df_long, aes(x = ID, y = Prob, fill = Clase)) +
  geom_col(width = 0.8) +
  # Superponer un contorno en la porción de máxima probabilidad
  geom_point(
    data = df_probs %>% 
      select(ID, Clase_dura) %>%
      left_join(
        df_long %>% 
          filter(Clase == Clase_dura) %>%
          group_by(ID) %>%
          summarize(y_max = Prob), 
        by = "ID"
      ),
    aes(x = ID, y = y_max),
    shape = 21, color = "black", fill = NA, size = 4, stroke = 1.2
  ) +
  coord_flip() + 
  scale_fill_manual(
    values = c(
      "Clase_1" = "#E8F5E9",  # pastel verde (inspirado en el verde palestino pero aclarado)
      "Clase_2" = "#FDE0DC",  # pastel rojo (inspirado en el rojo palestino pero aclarado)
      "Clase_3" = "#E0E0E0"   # pastel negro (gris claro)
      #       "Clase_1" = "#E8F5E9",  # pastel verde
      # "Clase_2" = "#FDE0DC",  # pastel rojo
      # "Clase_3" = "#E0E0E0"   # gris claro
    ),
    labels = c("Clase 1", "Clase 2", "Clase 3")
  ) +
  labs(
    subtitle = "Barras apiladas: probabilidades posteriores por Obs./\nPunto: clase asignada (mayor probabilidad)",
    x = NULL, y = "Probabilidad posterior",
    fill = "Clase"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11)
  )
```

:::

::::

::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`

- Clasificación dura= obs. en la clase a la que tienen más alta probabilidad de pertenecer
- la clasificación dura no considera la incertidumbre propia de la clasificación 
- lasificación dura (Hard-classification) a clases basados en la probabilidad posterior máxima es utilizada para describir las características y predictores más probables de las clases (Nagin 2005). Notar que este método asume un grado de incertidumbre, por lo que las clases identificadas es probabilístico más que real
- Las clases son reificadas como predictores de otros resultados de interés, tratando a la clase más común como la verdadera clase a la que pertenece el individuo aunque haya incertidumbre en la pertenencia a una clase, la que puede verse como una forma de error de medición en los predictores. El más común es el de dos etapas que trata un modelo de 2 etapas que trata a la predicción modal como la verdadera (Elliott et al 2020)
- - "assigning latent classes based on modal posterior probability of membership and treating them as fixed and known"

- Classify-analyze= Zhang, Z., Abarda, A., Contractor, A. A., Wang, J., & Dayton, C. M. (2018)
1. **Clasificar:** Se calcula la probabilidad posterior de cada paciente y se le asigna a la clase latente en la que tenga la mayor probabilidad.
2. **Analizar:** Se usa un modelo de regresión logística para analizar, incluyendo como variables la pertenencia a la clase latente, el tratamiento, y su interacción con el resultado que se quiere estudiar.


-  Si la entropía es >0.80, los resultados no variarán mucho entre los tipos de relaciones con otras variables. Eso denota una buena separación (también ver el tipo de clasificación que se utiliza para decir que una observación depende de una clase). A veces es 0,7 a veces es la moda, a veces es 0,5.
- In such circumstances, the loss of information introduced by this “classify-analyze” approach will be minimal (Sinha et al 2021)

- some guidelines have suggested that values on the diagonal should exceed 0.7 (Masyn, 2013). These guidelines should not be considered as strict cutoffs; rather, classification quality should be interpreted substantive (Van Lissa et al., 2023)

- Researchers often wish to relate class membership to auxiliary variables, or even auxiliary models. It is important to keep in mind that most likely class membership M is subject to classification error (Vermunt, 2010a). Treating class membership as an observed variable disregards this error, resulting in biased models, except when class separation is very high. It is therefore important to account for classification error in follow-up analyses. The BCH method, available via BCH(), compares auxiliary variables or arbitrary auxiliary models across classes while accounting for classification error (Bolck et al., 2004). 
- The current study proposes a step-by-step approach for using inverse propensity score weighting together with the “Bolck, Croon, and Hagenaars” approach to LCA with distal outcomes (i.e., the BCH approach)

- naming fallacy/falacia etiquetado= nombres muy simples pueden confundir (Weller et al., 2020; Van Lissa et al., 2023)

:::


## Taller

Abra el siguiente [**enlace al TALLER**](taller_aplicacion_lca.html)


## Buenas prácticas

- Razones para haber seleccionado los indicadores, si se basa en la teoría

- Si no, razones para haber generado un modelo exploratorio

- Características de los datos (descriptivos, datos perdidos) // patrones "salsa"

- Paquete estadístico y versión

- Método de estimación

- Criterios estadísticos y de interpretabilidad sustantiva para seleccionar el modelo

- Tablas que incluyan al menos dos criterios de ajuste, entropía yla proabilidad promedio

- Figura de clases identificadas

- Número de muestra o porcentaje de la muestra en cada clase

<div style="text-align: center; font-size: small; font-style: italic;"> Adaptado de: <a href="https://journals.sagepub.com/doi/full/10.1177/0095798420930932" target="_blank">Weller et al, 2020</a> </div>

::: {.notes}

- Cuidado con las **clasificaciones** tipo "sinsabor, algo picante, muy picante", que reflejan gradientes de puntajes interpretados como categóricos, porque deriva en que tratemos las variables manifiestas por grados. Esto sugiere que el modelo elegido no es el mejor para los datos [Vaya a la tabla del principio] (Wolf et al)
- En los plots tienden a verse probabilidades de respuesta paralelas para cada ítem, sólo diferenciando su intensidad de respuesta. Eso prende alarmas.
-Cuidado con el **supuesto de Independencia Local** (Sinha et al 2019): las variables son independientes unas de otras al interior de una clase latente. Muchas veces esto mismo genera el problema de arriba, en que sólo se pueden ver diferencias porque todos los item "cargan" pal mismo lado, sólo que unos sujetos más y otros menos.

- **Validez**= A veces en dos mitades (una base de exploración y otra de testeo para confirmar si el modelo sigue teniendo buen ajuste). Si se utiliza para predecir desenlaces por ejemplo, utilizar métricas apropiadas para evaluar la capacidad predictiva (el R2 es insuficiente, porque no es un modelo lineal) (Wolf et al)

- Para asegurarse que el orden de las clases se conservan, se generan una semilla (Van Lissa et al., 2023).

:::

## Extensiones

- Con datos longitudinales

- Con datos de supervivencia (tiempos de supervivencia heterogéneos; Li, 2019)

- Tener en cuenta efectos aleatorios de las variables por grupos

::: {.notes}
`r invisible("#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#")`

-**Long**: Puede capturar la heterogeneidad de las medidas repetidas en el tiempo
- Hay análisis de trayectorias. Se debe asegurar no sólo tener las mismas preguntas, sino que exista invarianza en la medición [funciona igual factorialmente el instrumento?] (Wolf et al)

- Latent Class Growth Analysis(LCGA), Cada persona queda asignada a la clase cuya curva de crecimiento “predice” mejor su propio perfil de medidas.

- LCGA differs from GMM in that it assumes within-class homogeneity of trajectories, restricting the (co)variances to zero. Another longitudinal extension of LCA is the **Hidden Markov** Model or Latent Transition Analysis, which estimates an LCA at each time point and models the probabilities of transitioning from one class to another (Vermunt, 2010b). 

:::

## Gracias

<div style="width: 100%; height: 100vh; display: flex; align-items: center; justify-content: center;">
<div style="text-align: center;">
  <span style="font-weight: bold; color: #FF0000;">r</span>
  <span style="font-weight: bold; color: #FFFFFF; text-shadow: -1px -1px 0 #000000, 1px -1px 0 #000000, -1px 1px 0 #000000, 1px 1px 0 #000000;">e</span>
  <span style="font-weight: bold; color: #008000;">s</span>
  <span style="font-weight: bold; color: #000000;">i</span>
  <span style="font-weight: bold; color: #FF0000;">g</span>
  <span style="font-weight: bold; color: #FFFFFF; text-shadow: -1px -1px 0 #000000, 1px -1px 0 #000000, -1px 1px 0 #000000, 1px 1px 0 #000000;">n</span>
  <span style="font-weight: bold; color: #008000;">,</span>
  <span>&nbsp;</span>
  <span style="font-weight: bold; color: #000000;">r</span>
  <span style="font-weight: bold; color: #FF0000;">e</span>
  <span style="font-weight: bold; color: #FFFFFF; text-shadow: -1px -1px 0 #000000, 1px -1px 0 #000000, -1px 1px 0 #000000, 1px 1px 0 #000000;">f</span>
  <span style="font-weight: bold; color: #008000;">u</span>
  <span style="font-weight: bold; color: #000000;">s</span>
  <span style="font-weight: bold; color: #FF0000;">e</span>
  <span style="font-weight: bold; color: #FFFFFF; text-shadow: -1px -1px 0 #000000, 1px -1px 0 #000000, -1px 1px 0 #000000, 1px 1px 0 #000000;">,</span>
  <span>&nbsp;</span>
  <span style="font-weight: bold; color: #008000;">r</span>
  <span style="font-weight: bold; color: #000000;">e</span>
  <span style="font-weight: bold; color: #FF0000;">d</span>
  <span style="font-weight: bold; color: #FFFFFF; text-shadow: -1px -1px 0 #000000, 1px -1px 0 #000000, -1px 1px 0 #000000, 1px 1px 0 #000000;">i</span>
  <span style="font-weight: bold; color: #008000;">r</span>
  <span style="font-weight: bold; color: #000000;">e</span>
  <span style="font-weight: bold; color: #FF0000;">c</span>
  <span style="font-weight: bold; color: #FFFFFF; text-shadow: -1px -1px 0 #000000, 1px -1px 0 #000000, -1px 1px 0 #000000, 1px 1px 0 #000000;">t</span>
  <span style="font-weight: bold; color: #008000;">!</span>
  <span style="font-weight: bold; color: #000000;">!</span>
</div>
</div>

::: {.notes}
“Renuncia a tu complicidad, rechaza la violencia estructural, y redirige tu energía hacia la justicia.”

:::


## Información de la sesión

<div style="font-size: 50%;">
```{r session_info, echo=T, paged.print=TRUE}
#guardamos la información generada
save.image("_data/palestine_25.RData")
#vemos desde donde se producen las librerías
Sys.getenv("R_LIBS_USER")
#ponemos información de la sesión: Sistema operativo, paquetes, idisioncracias, etc.
sessionInfo()
```
</div>


## Fuentes {.nonincremental}

<div style="font-size: 40%;">

- Arango Díaz, L. (2015). Práctica poLCA. RPubs. https://rpubs.com/liliana/94701
- Haughton, D., Legrand, P., & Woolford, S. (2009). Review of Three Latent Class Cluster Analysis Packages: Latent Gold, poLCA and MCLUST. The American Statistician, 63(1), 81-91. https://doi.org/10.1198/tast.2009.0016
- He, J., & Fan, X. (2019). Latent Class Analysis. In V. Zeigler-Hill & T. Shackelford (Eds.), Encyclopedia of Personality and Individual Differences (pp. 1-7). Springer, Cham. https://doi.org/10.1007/978-3-319-28099-8_2313-1
- Herle, M., Micali, N., Abdulkadir, M., Loos, R., Bryant-Waugh, R., Hübel, C., Bulik, C. M., & De Stavola, B. L. (2020). Identifying typical trajectories in longitudinal data: Modelling strategies and interpretations. European Journal of Epidemiology, 35(3), 205-222. https://doi.org/10.1007/s10654-020-00615-6
- Kimchi, A. (2019). Investigating the Assignment of Probation Conditions: Heterogeneity and the Role of Race and Ethnicity. Journal of Quantitative Criminology, 35, 715-745. https://doi.org/10.1007/s10940-018-9400-2
- Kongsted, A., & Nielsen, A. M. (2017). Latent Class Analysis in health research. Journal of Physiotherapy, 63(1), 55-58.
- Mantegazzini, A. (2019). An Introduction to Latent Class Modelling: LCM with Stata, how does it work? [Presentation]. Research Infrastructure for Science and Innovation Policy Studies (RISIS). https://www.risis2.eu/wp-content/uploads/2019/09/LCM-with-STATA_-Barbara_Antonioli_Mantegazzini_rev.pdf
- Nylund-Gibson, K., Garber, A. C., Carter, D. B., Chan, M., Arch, D. A. N., Simon, O., Whaling, K., Tartt, E., & Lawrie, S. I. (2023). Ten frequently asked questions about latent transition analysis. Psychological Methods, 28(2), 284-300. https://doi.org/10.1037/met0000486
- Oberski, D. (2015). Latent class analysis [PowerPoint slides]. Tilburg University. http://daob.nl/wp-content/uploads/2015/07/ESRA-course-slides.pdf
- Oberski, D. L. (2016). Mixture models: Latent profile and latent class analysis. In J. Robertson & M. Kaptein (Eds.), Modern Statistical Methods for HCI (pp. 275-287). Springer. https://doi.org/10.1007/978-3-319-26633-6_12
- Reyna, C., & Brussino, S. (2011). Revisión de los fundamentos del análisis de clases latentes y ejemplo de aplicación en el área de las adicciones. Trastornos Adictivos, 13(1), 11-19. https://doi.org/10.1016/s1575-0973(11)70004-6
- Schreiber, J. (2016). Latent Class Analysis: An example for reporting results. Research in Social and Administrative Pharmacy. https://doi.org/10.1016/j.sapharm.2016.11.011
- Sinha, P., Calfee, C. S., & Delucchi, K. L. (2021). Practitioner's Guide to Latent Class Analysis: Methodological Considerations and Common Pitfalls. Critical Care Medicine, 49(1), e63-e79. https://doi.org/10.1097/CCM.0000000000004710
- Smith, A. (s.f.). Latent class trajectory analysis. School of Physiotherapy and Exercise Science, Curtin University. https://opus-tjr.org.au/wp-content/uploads/2019/05/OPUS-Webinar_Trajectory-Analysis_Introduction.pdf
- Suffoletto, B., & Chung, T. (2016). Patterns of Change in Weekend Drinking Cognitions Among Non-Treatment-Seeking Young Adults During Exposure to a 12-Week Text Message Intervention. Journal of Studies on Alcohol and Drugs, 77(6), 914-923. https://doi.org/10.15288/jsad.2016.77.914
- Weller, B. E., Bowen, N. K., & Faubert, S. J. (2020). Latent Class Analysis: A Guide to Best Practice. Journal of Black Psychology, 46(4), 287-311.
- Zhang, Z., Abarda, A., Contractor, A., Wang, J., & Dayton, C. (2018). Exploring heterogeneity in clinical trials with latent class analysis. Annals of Translational Medicine, 6(7). https://doi.org/10.21037/18822
- R. Weldon, W. F. "On Certain Correlated Variations in Carcinus Maenas on JSTOR." Proceedings of the Royal Society of London, 318. Accessed April 8, 2025. https://doi.org/115537.
- Madrid Casado, C. M. (2014). Fisher, la inferencia estadística: probablemente sí, probablemente no. Barcelona: RBA.
- Wolf, E. J., et al. (2025). What is latent about trauma exposure? Commentary on the use of latent class analysis for identifying trauma subtypes. Journal of Mood & Anxiety Disorders, 0(0), 100130. DOI: 10.1016/j.xjmad.2025.100130
- Cislo, P. R., Emir, B., Cabrera, J., Li, B., &amp; Alemayehu, D. (2021). Finite Mixture Models, a Flexible Alternative to Standard Modeling Techniques for Extrapolated Mean Survival Times Needed for Cost-Effectiveness Analyses. In Value in Health (Vol. 24, 11, pp. 1643–1650). Elsevier BV. https://doi.org/10.1016/j.jval.2021.05.012
- Li, B. Y. (2019). Finite mixture models in survival data analysis (Doctoral dissertation, Rutgers, The State University of New Jersey). Retrieved from https://rucore.libraries.rutgers.edu/rutgers-lib/61793/PDF/1/play/
- Elliott, M. R., Zhao, Z., Mukherjee, B., Kanaya, A., & Needham, B. L. (2020). Methods to Account for Uncertainty in Latent Class Assignments When Using Latent Classes as Predictors in Regression Models, with Application to Acculturation Strategy Measures. Epidemiology (Cambridge, Mass.), 31(2), 194–204. https://doi.org/10.1097/EDE.0000000000001139
. Van Lissa, C. J., Garnier-Villarreal, M., & Anadria, D. (2023). Recommended Practices in Latent Class Analysis Using the Open-Source R-Package tidySEM. Structural Equation Modeling: A Multidisciplinary Journal, 31(3), 526–534. https://doi.org/10.1080/10705511.2023.2250920
</div>